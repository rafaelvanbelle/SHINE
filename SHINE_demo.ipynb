{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc1369d8",
   "metadata": {},
   "source": [
    "# âœ¨ SHINE DEMO "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfb77e0",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f05b327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import uuid\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "# Torch Geometric\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "from torch_geometric.nn import SAGEConv, to_hetero, Linear\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "# FUCC metrics\n",
    "from fucc.metrics import log_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e127a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./code\")\n",
    "\n",
    "from utils import EarlyStopping, HeteroSubgraph\n",
    "from fraud_dataloader import HeteroFraudSubset\n",
    "from custom_neighbor_loader import NeighborLoader\n",
    "from models import HeteroGraphSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "062856d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dedc80ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train_shape (1275446, 61)\n",
      "df_val_shape (141717, 61)\n",
      "df_test_shape (282415, 61)\n",
      "df_train_shape (1275446, 61)\n",
      "df_val_shape (141717, 61)\n",
      "df_test_shape (282415, 61)\n",
      "(1699578, 61)\n",
      "False    1697010\n",
      "True        2568\n",
      "Name: Is Fraud?, dtype: int64\n",
      "1699578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = HeteroFraudSubset(root='./data', subset=subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c4c7864",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ed316c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mtransaction\u001b[0m={\n",
       "    x=[1699578, 31],\n",
       "    y=[1699578],\n",
       "    train_mask=[1699578],\n",
       "    val_mask=[1699578],\n",
       "    test_mask=[1699578]\n",
       "  },\n",
       "  \u001b[1mcardholder\u001b[0m={ x=[1531, 1] },\n",
       "  \u001b[1mmerchant\u001b[0m={ x=[34804, 1] },\n",
       "  \u001b[1m(cardholder, pays, transaction)\u001b[0m={ edge_index=[2, 1699578] },\n",
       "  \u001b[1m(merchant, receives, transaction)\u001b[0m={ edge_index=[2, 1699578] }\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3d3d084",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Environment\n",
    "num_workers = 10\n",
    "\n",
    "\n",
    "# other\n",
    "train_size = '300d'\n",
    "test_size = '60d'\n",
    "\n",
    "#Model\n",
    "num_neighbors = [2,32] \n",
    "num_hidden_channels = 64\n",
    "sage_aggr = 'add'\n",
    "hetero_aggr = 'sum'\n",
    "concat = False\n",
    "project = False\n",
    "dropout = False\n",
    "normalize = False\n",
    "\n",
    "\n",
    "# weighted neighbor sampling \n",
    "weighted = False\n",
    "weight_func = None #'sub' #('add', 'mul', 'sub')\n",
    "skip = False\n",
    "exp = False\n",
    "\n",
    "#Learning\n",
    "learning_rate = 0.00001 # worldline: 0.00001 ibm_ai: 0.0001\n",
    "batch_size = 500\n",
    "max_epochs = 2\n",
    "patience = 5\n",
    "delta = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91193ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'batch_size': batch_size, 'num_workers': num_workers, 'persistent_workers': True} #pin_memory=True (only set pin_memory=True if dataset does not fit in GPU entirely)\n",
    "number_of_positives = int(test_size[:-1])*150\n",
    "num_layers = len(num_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c673caa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_path = os.path.join(base_path ,  \"data/fraudsage\")\n",
    "#output_path_model = (os.path.join(data_path, \"models\", str(dataset_name), str(setting), str(train_size) + '_' + str(test_size)))\n",
    "#root = os.path.join(data_path, \"subsets\", str(dataset_name), str(train_size) + '_' + str(test_size) )\n",
    "# we add a random string to the model filename to differentiate between multiple models of runs running concurrently.\n",
    "#rnd_str = str(uuid.uuid4())\n",
    "#filename_model = '_'.join(['subset', str(subset), 'run_id',  str(run_id), rnd_str])\n",
    "\n",
    "#try:\n",
    "#    os.makedirs(output_path_model)\n",
    "#except:\n",
    "#    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072eed59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4724b897",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd2478b",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e3848a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = T.ToUndirected()(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4af0d722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mtransaction\u001b[0m={\n",
       "    x=[1699578, 31],\n",
       "    y=[1699578],\n",
       "    train_mask=[1699578],\n",
       "    val_mask=[1699578],\n",
       "    test_mask=[1699578]\n",
       "  },\n",
       "  \u001b[1mcardholder\u001b[0m={ x=[1531, 1] },\n",
       "  \u001b[1mmerchant\u001b[0m={ x=[34804, 1] },\n",
       "  \u001b[1m(cardholder, pays, transaction)\u001b[0m={ edge_index=[2, 1699578] },\n",
       "  \u001b[1m(merchant, receives, transaction)\u001b[0m={ edge_index=[2, 1699578] },\n",
       "  \u001b[1m(transaction, rev_pays, cardholder)\u001b[0m={ edge_index=[2, 1699578] },\n",
       "  \u001b[1m(transaction, rev_receives, merchant)\u001b[0m={ edge_index=[2, 1699578] }\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if data fits on GPU, move it!\n",
    "data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24cd8a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0785, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000],\n",
       "        [0.0722, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000],\n",
       "        [0.0766, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0719, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0731, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000],\n",
       "        [0.0779, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['transaction'].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b59a189b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1275446])\n",
      "tensor(1892)\n"
     ]
    }
   ],
   "source": [
    "# Test set statistics \n",
    "transaction_data = data['transaction']\n",
    "print(transaction_data.y[transaction_data.train_mask].size())\n",
    "print(transaction_data.y[transaction_data.train_mask].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cfc74e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([282415])\n",
      "tensor(447)\n"
     ]
    }
   ],
   "source": [
    "# Test set statistics \n",
    "print(transaction_data.y[transaction_data.test_mask].size())\n",
    "print(transaction_data.y[transaction_data.test_mask].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7f5ee9",
   "metadata": {},
   "source": [
    "## Inductive preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63aa6658",
   "metadata": {},
   "source": [
    "There are two important *inductive* preprocessing steps:\n",
    "\n",
    "1. **the train/val/test split** has to be inductive. In other words, the validation and test nodes should be separated from the training nodes. During training, the validation and test nodes cannot be observed! \n",
    "\n",
    "2. **time gap**: when the model is trained, we only know the true label for the first portion of our transaction nodes. The most recent training transactions are too recent to have a fixed label (they are still under investigation). Hence, we *mask* the labels of all transactions in the x most recent training days. They can still be observed by the algorithm and used in the neighborhood exploration, but their labels are unknown!\n",
    "\n",
    "**Note**: In the *transductive setting* all nodes are present in the network. The training is limited to the nodes designated as training nodes, nevertheless during neighorhood exploration they can use the validation and test nodes!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81910663",
   "metadata": {},
   "source": [
    "### Train/Val/Test split "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267797e3",
   "metadata": {},
   "source": [
    "Create a train/val/test graph\n",
    "\n",
    "We only sample the transactions! \n",
    "Train data contains train transactions\n",
    "Val data contains train and val transactions\n",
    "Test data contains train, val and test transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3a24b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "cardholder_mask = torch.Tensor([True] * data['cardholder'].x.size(0)).bool().to(device)\n",
    "merchant_mask = torch.Tensor([True] * data['merchant'].x.size(0)).bool().to(device)\n",
    "\n",
    "node_mask_dict_train = {'transaction': data['transaction'].train_mask, 'cardholder': cardholder_mask, 'merchant': merchant_mask}\n",
    "node_mask_dict_val = {'transaction': (data['transaction'].train_mask + data['transaction'].val_mask), 'cardholder': cardholder_mask, 'merchant': merchant_mask}\n",
    "node_mask_dict_test = {'transaction': (data['transaction'].train_mask + data['transaction'].val_mask + data['transaction'].test_mask), 'cardholder': cardholder_mask, 'merchant': merchant_mask}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7865e394",
   "metadata": {},
   "source": [
    "The Subgraph function filters the edges to only include those that link nodes which are in the node_mask_dict. \n",
    "E.g. for train_data -> node_mask_dict_train contains the training transactions, all cardholders and all merchants\n",
    "Only the edges linking these nodes are retained. Hence, no validation or test transactions are in the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80c5e6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no need to take deepcopy of data as this is done inside the subgraph function\n",
    "train_data = HeteroSubgraph(data, node_mask_dict_train, weighted=weighted)\n",
    "val_data = HeteroSubgraph(data, node_mask_dict_val, weighted=weighted)\n",
    "test_data = HeteroSubgraph(data, node_mask_dict_test, weighted=weighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfd3516",
   "metadata": {},
   "source": [
    "### Time gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41ac6179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what happens if we cut half of the train set. Only first part can be used. \n",
    "# By introducing this gap, we mimic the real life situation in which fraud label is not known instantly. \n",
    "train_percentage = 1 - (8/int(train_size[:-1]))\n",
    "\n",
    "cutoff = int(data['transaction'].train_mask.count_nonzero() * train_percentage)\n",
    "train_input_nodes_mask = torch.tensor(np.zeros(data['transaction'].train_mask.size()[0])).bool()\n",
    "train_input_nodes_mask[:cutoff] = True\n",
    "train_input_nodes = ('transaction', train_input_nodes_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e4f9e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_input_nodes = ('transaction', data['transaction'].val_mask)\n",
    "test_input_nodes = ('transaction', data['transaction'].test_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0ad09a",
   "metadata": {},
   "source": [
    "## Data Loaders with Neighbor Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20d7338a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = NeighborLoader(train_data, input_nodes=train_input_nodes ,\n",
    "                              num_neighbors=num_neighbors, shuffle=True, skip=skip,  weight_func = weight_func, exp=exp, **kwargs)\n",
    "val_loader = NeighborLoader(val_data, input_nodes= val_input_nodes,\n",
    "                              num_neighbors=num_neighbors, shuffle=False, skip=skip,  weight_func = weight_func, exp=exp, **kwargs)\n",
    "test_loader = NeighborLoader(test_data, input_nodes= test_input_nodes,\n",
    "                              num_neighbors=num_neighbors, shuffle=False, skip=skip,  weight_func = weight_func, exp=exp, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23c3194",
   "metadata": {},
   "source": [
    "## Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46b4b805",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HeteroGraphSAGE(num_hidden_channels, \n",
    "                out_channels=1, \n",
    "                num_layers=len(num_neighbors), \n",
    "                num_features= data.num_features, \n",
    "                metadata=data.metadata(), \n",
    "                dropout=dropout, \n",
    "                project=project, \n",
    "                hetero_aggr = hetero_aggr,\n",
    "                sage_aggr = sage_aggr,\n",
    "                normalize = normalize)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a37db13a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroGraphSAGE(\n",
       "  (convs): ModuleList(\n",
       "    (0): HeteroConv(num_relations=4)\n",
       "    (1): HeteroConv(num_relations=4)\n",
       "  )\n",
       "  (lin): Linear(-1, 1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5f54234",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def init_params():\n",
    "    # Initialize lazy parameters via forwarding a single batch to the model:\n",
    "    batch = next(iter(train_loader))\n",
    "    batch = batch.to(device)\n",
    "    model(batch.x_dict, batch.edge_index_dict)\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    total_examples = total_loss = 0\n",
    "    for batch in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        batch = batch.to(device)\n",
    "        batch_size = batch['transaction'].batch_size\n",
    "        out = model(batch.x_dict, batch.edge_index_dict)[:batch_size]\n",
    "        \n",
    "        loss = criterion(out.squeeze(1), batch['transaction'].y[:batch_size].float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_examples += batch_size\n",
    "        total_loss += float(loss) * batch_size\n",
    "\n",
    "    return total_loss / total_examples\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader, feature_list=None):\n",
    "    model.eval()\n",
    "    \n",
    "\n",
    "    \n",
    "    y_pred_probas = []\n",
    "    y_trues = []\n",
    "    \n",
    "    total_examples = total_loss = 0\n",
    "\n",
    "    for batch in tqdm(loader):\n",
    "        batch = batch.to(device)\n",
    "        batch_size = batch['transaction'].batch_size\n",
    "        y = batch['transaction'].y[:batch_size]\n",
    "        y_hat = model(batch.x_dict, batch.edge_index_dict)[:batch_size]\n",
    "        loss = criterion(y_hat.squeeze(1), y.float())\n",
    "        \n",
    "        total_examples += batch_size\n",
    "        total_loss += float(loss) * batch_size\n",
    "        y_pred_probas.append(torch.sigmoid(y_hat.cpu()))\n",
    "        y_trues.append(y.cpu())\n",
    "        \n",
    "\n",
    "    y_true = np.concatenate(y_trues)\n",
    "    y_pred_proba = np.concatenate(y_pred_probas)\n",
    "    \n",
    "    return y_true, y_pred_proba, total_loss/total_examples\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6756e2c2",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f92d976",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# loss function\n",
    "#criterion = torch.nn.CrossEntropyLoss()\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "# initialize Early Stopping\n",
    "early_stopping = EarlyStopping(patience=patience, verbose=True, delta=delta, path='checkpoint.pt')\n",
    "\n",
    "init_params()  # Initialize parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3de6ee44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2483/2483 [04:07<00:00, 10.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00, Loss: 0.1565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2483/2483 [02:23<00:00, 17.36it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 284/284 [00:31<00:00,  8.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.012887).  Saving model ...\n",
      "Epoch 00, AP train: 0.0019, AP test: 0.0028\n",
      "Epoch 00, ROC train: 0.5927, ROC test: 0.6804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2483/2483 [04:26<00:00,  9.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01, Loss: 0.0113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2483/2483 [02:08<00:00, 19.35it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 284/284 [00:14<00:00, 20.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.012887 --> 0.010750).  Saving model ...\n",
      "Epoch 01, AP train: 0.0077, AP test: 0.0164\n",
      "Epoch 01, ROC train: 0.7357, ROC test: 0.8120\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(max_epochs):\n",
    "    \n",
    "    loss = train()\n",
    "    \n",
    "    print(f'Epoch {epoch:02d}, Loss: {loss:.4f}') # , Approx. Train: {acc:.4f}')\n",
    "    \n",
    "    y_train, y_train_pred_proba, train_loss = test(train_loader) \n",
    "    y_val, y_val_pred_proba, val_loss = test(val_loader)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # early_stopping needs the validation loss to check if it has decresed, \n",
    "        # and if it has, it will make a checkpoint of the current model\n",
    "    early_stopping(val_loss, model, epoch)\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "        \n",
    "    \n",
    "    # Average precision\n",
    "    ap_train = average_precision_score(y_train, y_train_pred_proba)\n",
    "    ap_val = average_precision_score(y_val, y_val_pred_proba)\n",
    "    \n",
    "    # ROC\n",
    "    roc_train = roc_auc_score(y_train, y_train_pred_proba)\n",
    "    roc_val = roc_auc_score(y_val, y_val_pred_proba)\n",
    "    \n",
    "    \n",
    "    print(f'Epoch {epoch:02d}, AP train: {ap_train:.4f}, AP test: {ap_val:.4f}')\n",
    "    print(f'Epoch {epoch:02d}, ROC train: {roc_train:.4f}, ROC test: {roc_val:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473f41f6",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df72a059",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03bff0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 565/565 [00:52<00:00, 10.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.028525297185399433\n",
      "0.7840098725722093\n"
     ]
    }
   ],
   "source": [
    "# load the last checkpoint with the best model\n",
    "model.load_state_dict(torch.load(early_stopping.path))\n",
    "\n",
    "test_loader_non_shuffled = NeighborLoader(data, input_nodes=test_input_nodes ,\n",
    "                              num_neighbors=num_neighbors, shuffle=False, skip=skip, weight_func = weight_func, exp=exp,  **kwargs)\n",
    "y_true_test, y_pred_proba_test, test_loss = test(test_loader_non_shuffled)\n",
    "ap_test = average_precision_score(y_true_test, y_pred_proba_test)\n",
    "roc_test = roc_auc_score(y_true_test, y_pred_proba_test)\n",
    "\n",
    "print(ap_test)\n",
    "print(roc_test)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "pytorch_nightly",
   "language": "python",
   "name": "pytorch_nightly"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
